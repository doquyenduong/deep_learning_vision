{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TextGenerator_GPT2_FineTuneModel.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","toc_visible":true,"authorship_tag":"ABX9TyOIV8+cDL9d/0qDCgkaH37O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"135bdc97986b448794d423f51a84ccd0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_92818a6f245d4369b43161c50bbd81a4","IPY_MODEL_859ad41dbd564b2194b88dc6481cc8fd","IPY_MODEL_583cfac201f940e69cff5259b014c203"],"layout":"IPY_MODEL_b0c909197fbd4dd1a2fbd56ac91656ba"}},"92818a6f245d4369b43161c50bbd81a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8eeef03f573e46aa8b7f6d177a85888d","placeholder":"​","style":"IPY_MODEL_752d3c284ff24db1be6be91ece374c11","value":"Downloading: 100%"}},"859ad41dbd564b2194b88dc6481cc8fd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f3009c38ae14d1a8f46aaea4c6dbd7c","max":548118077,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9f0cf97323724bbb82ad4c9240911849","value":548118077}},"583cfac201f940e69cff5259b014c203":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_254d9c547ca04b7084eab92f854ce56f","placeholder":"​","style":"IPY_MODEL_ab593ac980cb428a96e83ff371fe4279","value":" 523M/523M [00:08&lt;00:00, 70.4MB/s]"}},"b0c909197fbd4dd1a2fbd56ac91656ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8eeef03f573e46aa8b7f6d177a85888d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"752d3c284ff24db1be6be91ece374c11":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f3009c38ae14d1a8f46aaea4c6dbd7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f0cf97323724bbb82ad4c9240911849":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"254d9c547ca04b7084eab92f854ce56f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab593ac980cb428a96e83ff371fe4279":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Blogpost Article Generator - Transformer GPT-2\n","Author: Amelia Budiharto, Mark Cannel, Pascal Waser, Quyen Duong"],"metadata":{"id":"TqPeoL2eJX5d"}},{"cell_type":"markdown","source":["## 1. Background Information\n","This notebook presents the code of text genetator for a blogpost article. The model trained using a article text under the category of technology. We used pre-trained transformer model (+1.5 billions datapoints). As a result, it aims to generate the next sequence of words based on the input keyword that we give in the beginning by fine-tuning GPT-2 model."],"metadata":{"id":"GHbVr2YXJJSr"}},{"cell_type":"markdown","source":["## 1. Preparation"],"metadata":{"id":"g4rl5clQHCQG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"iJFEv8wgLwyI"},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, random_split\n","from transformers import GPT2Tokenizer, TrainingArguments, Trainer, GPT2LMHeadModel"],"metadata":{"id":"RCRK4KQSL5w2","executionInfo":{"status":"ok","timestamp":1656424146195,"user_tz":-120,"elapsed":4450,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Set seed for reproducability purpose\n","\n","torch.manual_seed(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fr0YmokbMXAK","executionInfo":{"status":"ok","timestamp":1656424146195,"user_tz":-120,"elapsed":12,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}},"outputId":"ba8b3733-0283-481f-fe5e-99eb96981e77"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f0e294a70d0>"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["# Check whether the CUDA driver is available or not\n","\n","torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P26UzNgVMd2M","executionInfo":{"status":"ok","timestamp":1656424146196,"user_tz":-120,"elapsed":9,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}},"outputId":"fc668a1b-f1f1-45b7-84aa-b251cc7d2399"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["## 2. Load Pre-trained Model and Training Dataset\n","There are several GPT2 module. In this case, we use the generic GPT2 module."],"metadata":{"id":"sXo880QFHUWr"}},{"cell_type":"code","source":["tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>',\n","                                          eos_token='<|endoftext|>', pad_token='<|pad|>')\n","model = GPT2LMHeadModel.from_pretrained('gpt2').cuda()\n","model.resize_token_embeddings(len(tokenizer))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["135bdc97986b448794d423f51a84ccd0","92818a6f245d4369b43161c50bbd81a4","859ad41dbd564b2194b88dc6481cc8fd","583cfac201f940e69cff5259b014c203","b0c909197fbd4dd1a2fbd56ac91656ba","8eeef03f573e46aa8b7f6d177a85888d","752d3c284ff24db1be6be91ece374c11","2f3009c38ae14d1a8f46aaea4c6dbd7c","9f0cf97323724bbb82ad4c9240911849","254d9c547ca04b7084eab92f854ce56f","ab593ac980cb428a96e83ff371fe4279"]},"id":"EM5ws-XPMd5R","executionInfo":{"status":"ok","timestamp":1656424167855,"user_tz":-120,"elapsed":21664,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}},"outputId":"528a50a7-8554-44ea-dd43-eeaf8bae32e0"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/523M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"135bdc97986b448794d423f51a84ccd0"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["Embedding(50259, 768)"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["Import the clean dataset that already transformed on the 'TextGenerator_Bidirectional_RNN_WordSequence' notebook "],"metadata":{"id":"btS9zGHeKIf6"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MczQeIsbN8dy","executionInfo":{"status":"ok","timestamp":1656424170872,"user_tz":-120,"elapsed":3028,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}},"outputId":"a88b31aa-767e-4c5b-e8e9-f563a2ede434"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%cd /content/drive/My Drive/Colab Notebooks/DeepLearningVision/Data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j2KAuKGnN8gN","executionInfo":{"status":"ok","timestamp":1656424170872,"user_tz":-120,"elapsed":22,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}},"outputId":"981fbfe1-bfab-4074-9181-e79c92a7fa0a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/DeepLearningVision/Data\n"]}]},{"cell_type":"code","source":["# Load clean text to avoid running above codes\n","\n","my_file = open(\"/content/drive/My Drive/Colab Notebooks/DeepLearningVision/Data/clean_text_tech_news.txt\", \"r\")\n","content = my_file.read()\n","\n","corpus = content.split(\",\")\n","my_file.close()"],"metadata":{"id":"PT_QOf8mNmo9","executionInfo":{"status":"ok","timestamp":1656424170873,"user_tz":-120,"elapsed":19,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Transform the dataset into pandas series\n","\n","descriptions = pd.Series(corpus)\n","\n","type(descriptions)"],"metadata":{"id":"SyifU3raOEps","executionInfo":{"status":"ok","timestamp":1656424170873,"user_tz":-120,"elapsed":18,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["descriptions"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fAfE9MCqQEwf","executionInfo":{"status":"ok","timestamp":1656424170874,"user_tz":-120,"elapsed":14,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}},"outputId":"abc2c1f9-bfb4-4df7-91ba-ba0493846a85"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0          madden espn football score in different way ...\n","1        group to propose new high speed wireless forma...\n","2        aol to sell cheap pcs to minority and senior a...\n","3        company approve new high capacity disc format ...\n","4        miss june deal slow to return for software cos...\n","                               ...                        \n","29996    digitize and bring to life digital technology ...\n","29997    new computer six step to safe surfing to see t...\n","29998    video file present search challenge indexing w...\n","29999    compromise seal climate meeting climate confer...\n","30000                                                     \n","Length: 30001, dtype: object"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["## 3. Prepare Input Features for fine-tuning GPT-2 Model"],"metadata":{"id":"i5rKGxRPHoRl"}},{"cell_type":"code","source":["# Tokenize the sentence\n","\n","max_length = max([len(tokenizer.encode(description)) for description in descriptions])\n","\n","class NewsDataset(Dataset):\n","    def __init__(self, txt_list, tokenizer, max_length):\n","        self.input_ids = []\n","        self.attn_masks = []\n","        self.labels = []\n","        for txt in txt_list:\n","            encodings_dict = tokenizer('<|startoftext|>' + txt + '<|endoftext|>', truncation=True,\n","                                       max_length=max_length, padding=\"max_length\")\n","            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n","            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        return self.input_ids[idx], self.attn_masks[idx]"],"metadata":{"id":"gWIqysfqOfv8","executionInfo":{"status":"ok","timestamp":1656424181434,"user_tz":-120,"elapsed":17,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Split dataset\n","\n","dataset = NewsDataset(descriptions, tokenizer, max_length=max_length)\n","train_size = int(0.9 * len(dataset))\n","train_dataset, val_dataset = random_split(dataset, [train_size, len(dataset) - train_size])"],"metadata":{"id":"dcd5z28uOfym","executionInfo":{"status":"ok","timestamp":1656424194247,"user_tz":-120,"elapsed":12829,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Collect the garbage to empty the cuda cache\n","\n","import gc\n","gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"REM_mdKdOf1X","executionInfo":{"status":"ok","timestamp":1656424194248,"user_tz":-120,"elapsed":31,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}},"outputId":"810a3bc6-7853-4ab1-dd09-fbba7461c52c"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["149"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# Empty the cuda cache\n","\n","torch.cuda.empty_cache()"],"metadata":{"id":"WnwRalX6OnFK","executionInfo":{"status":"ok","timestamp":1656424194262,"user_tz":-120,"elapsed":42,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["## 4. Train Model"],"metadata":{"id":"IOfADC9HImlK"}},{"cell_type":"code","source":["training_args = TrainingArguments(output_dir='/content/drive/My Drive/Colab Notebooks/DeepLearningVision/GPTresults', num_train_epochs=1, logging_steps=100, save_steps=5000,\n","                                  per_device_train_batch_size=1, per_device_eval_batch_size=1,\n","                                  warmup_steps=10, weight_decay=0.05, logging_dir='/content/drive/My Drive/Colab Notebooks/DeepLearningVision/GPTresults/logs', report_to = 'none')"],"metadata":{"id":"nCljDGdFOnHu","executionInfo":{"status":"ok","timestamp":1656424194263,"user_tz":-120,"elapsed":42,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["Trainer(model=model, args=training_args, train_dataset=train_dataset, \n","        eval_dataset=val_dataset, data_collator=lambda data: {'input_ids': torch.stack([f[0] for f in data]),\n","                                                              'attention_mask': torch.stack([f[1] for f in data]),\n","                                                              'labels': torch.stack([f[0] for f in data])}).train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"jiua4kAoOnKM","executionInfo":{"status":"ok","timestamp":1656427397246,"user_tz":-120,"elapsed":3195665,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}},"outputId":"7fa8fc6d-c62a-4e00-e571-f20d0f9fa090"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 27000\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 1\n","  Total train batch size (w. parallel, distributed & accumulation) = 1\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 27000\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='27000' max='27000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [27000/27000 53:14, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>3.074100</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.192800</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.170700</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.123100</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.083000</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>1.001100</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>1.015100</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>1.031800</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>1.020800</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.954800</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>1.017100</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.975000</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.976800</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>1.031600</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.968400</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.926200</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.957900</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.983000</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.981900</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.948500</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>0.979200</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>0.955500</td>\n","    </tr>\n","    <tr>\n","      <td>2300</td>\n","      <td>0.968400</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>0.944900</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.943500</td>\n","    </tr>\n","    <tr>\n","      <td>2600</td>\n","      <td>0.972100</td>\n","    </tr>\n","    <tr>\n","      <td>2700</td>\n","      <td>0.921900</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>0.897400</td>\n","    </tr>\n","    <tr>\n","      <td>2900</td>\n","      <td>0.930300</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.892600</td>\n","    </tr>\n","    <tr>\n","      <td>3100</td>\n","      <td>0.933900</td>\n","    </tr>\n","    <tr>\n","      <td>3200</td>\n","      <td>0.898200</td>\n","    </tr>\n","    <tr>\n","      <td>3300</td>\n","      <td>0.896100</td>\n","    </tr>\n","    <tr>\n","      <td>3400</td>\n","      <td>0.934800</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.925200</td>\n","    </tr>\n","    <tr>\n","      <td>3600</td>\n","      <td>0.920600</td>\n","    </tr>\n","    <tr>\n","      <td>3700</td>\n","      <td>0.909200</td>\n","    </tr>\n","    <tr>\n","      <td>3800</td>\n","      <td>0.904500</td>\n","    </tr>\n","    <tr>\n","      <td>3900</td>\n","      <td>0.920200</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.875900</td>\n","    </tr>\n","    <tr>\n","      <td>4100</td>\n","      <td>0.905500</td>\n","    </tr>\n","    <tr>\n","      <td>4200</td>\n","      <td>0.954300</td>\n","    </tr>\n","    <tr>\n","      <td>4300</td>\n","      <td>0.932200</td>\n","    </tr>\n","    <tr>\n","      <td>4400</td>\n","      <td>1.016900</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.898100</td>\n","    </tr>\n","    <tr>\n","      <td>4600</td>\n","      <td>0.932000</td>\n","    </tr>\n","    <tr>\n","      <td>4700</td>\n","      <td>0.927900</td>\n","    </tr>\n","    <tr>\n","      <td>4800</td>\n","      <td>0.805600</td>\n","    </tr>\n","    <tr>\n","      <td>4900</td>\n","      <td>0.924100</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.960300</td>\n","    </tr>\n","    <tr>\n","      <td>5100</td>\n","      <td>0.889300</td>\n","    </tr>\n","    <tr>\n","      <td>5200</td>\n","      <td>0.884500</td>\n","    </tr>\n","    <tr>\n","      <td>5300</td>\n","      <td>0.893400</td>\n","    </tr>\n","    <tr>\n","      <td>5400</td>\n","      <td>0.904900</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.929900</td>\n","    </tr>\n","    <tr>\n","      <td>5600</td>\n","      <td>0.863000</td>\n","    </tr>\n","    <tr>\n","      <td>5700</td>\n","      <td>0.886000</td>\n","    </tr>\n","    <tr>\n","      <td>5800</td>\n","      <td>0.868300</td>\n","    </tr>\n","    <tr>\n","      <td>5900</td>\n","      <td>0.904100</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.875000</td>\n","    </tr>\n","    <tr>\n","      <td>6100</td>\n","      <td>0.868200</td>\n","    </tr>\n","    <tr>\n","      <td>6200</td>\n","      <td>0.865200</td>\n","    </tr>\n","    <tr>\n","      <td>6300</td>\n","      <td>0.869700</td>\n","    </tr>\n","    <tr>\n","      <td>6400</td>\n","      <td>0.903300</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.895000</td>\n","    </tr>\n","    <tr>\n","      <td>6600</td>\n","      <td>0.863800</td>\n","    </tr>\n","    <tr>\n","      <td>6700</td>\n","      <td>0.844200</td>\n","    </tr>\n","    <tr>\n","      <td>6800</td>\n","      <td>0.852300</td>\n","    </tr>\n","    <tr>\n","      <td>6900</td>\n","      <td>0.896600</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.946500</td>\n","    </tr>\n","    <tr>\n","      <td>7100</td>\n","      <td>0.870000</td>\n","    </tr>\n","    <tr>\n","      <td>7200</td>\n","      <td>0.882100</td>\n","    </tr>\n","    <tr>\n","      <td>7300</td>\n","      <td>0.868400</td>\n","    </tr>\n","    <tr>\n","      <td>7400</td>\n","      <td>0.867800</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.931300</td>\n","    </tr>\n","    <tr>\n","      <td>7600</td>\n","      <td>0.876100</td>\n","    </tr>\n","    <tr>\n","      <td>7700</td>\n","      <td>0.892300</td>\n","    </tr>\n","    <tr>\n","      <td>7800</td>\n","      <td>0.904400</td>\n","    </tr>\n","    <tr>\n","      <td>7900</td>\n","      <td>0.840800</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.923100</td>\n","    </tr>\n","    <tr>\n","      <td>8100</td>\n","      <td>0.885600</td>\n","    </tr>\n","    <tr>\n","      <td>8200</td>\n","      <td>0.907300</td>\n","    </tr>\n","    <tr>\n","      <td>8300</td>\n","      <td>0.861400</td>\n","    </tr>\n","    <tr>\n","      <td>8400</td>\n","      <td>0.869100</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.857700</td>\n","    </tr>\n","    <tr>\n","      <td>8600</td>\n","      <td>0.910100</td>\n","    </tr>\n","    <tr>\n","      <td>8700</td>\n","      <td>0.858100</td>\n","    </tr>\n","    <tr>\n","      <td>8800</td>\n","      <td>0.801800</td>\n","    </tr>\n","    <tr>\n","      <td>8900</td>\n","      <td>0.885100</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.865300</td>\n","    </tr>\n","    <tr>\n","      <td>9100</td>\n","      <td>0.862200</td>\n","    </tr>\n","    <tr>\n","      <td>9200</td>\n","      <td>0.856900</td>\n","    </tr>\n","    <tr>\n","      <td>9300</td>\n","      <td>0.843300</td>\n","    </tr>\n","    <tr>\n","      <td>9400</td>\n","      <td>0.874800</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.833900</td>\n","    </tr>\n","    <tr>\n","      <td>9600</td>\n","      <td>0.948100</td>\n","    </tr>\n","    <tr>\n","      <td>9700</td>\n","      <td>0.850900</td>\n","    </tr>\n","    <tr>\n","      <td>9800</td>\n","      <td>0.840000</td>\n","    </tr>\n","    <tr>\n","      <td>9900</td>\n","      <td>0.847500</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.863400</td>\n","    </tr>\n","    <tr>\n","      <td>10100</td>\n","      <td>0.918600</td>\n","    </tr>\n","    <tr>\n","      <td>10200</td>\n","      <td>0.871700</td>\n","    </tr>\n","    <tr>\n","      <td>10300</td>\n","      <td>0.843800</td>\n","    </tr>\n","    <tr>\n","      <td>10400</td>\n","      <td>0.863700</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>0.918100</td>\n","    </tr>\n","    <tr>\n","      <td>10600</td>\n","      <td>0.918100</td>\n","    </tr>\n","    <tr>\n","      <td>10700</td>\n","      <td>0.829300</td>\n","    </tr>\n","    <tr>\n","      <td>10800</td>\n","      <td>0.849300</td>\n","    </tr>\n","    <tr>\n","      <td>10900</td>\n","      <td>0.808700</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>0.902700</td>\n","    </tr>\n","    <tr>\n","      <td>11100</td>\n","      <td>0.890700</td>\n","    </tr>\n","    <tr>\n","      <td>11200</td>\n","      <td>0.946200</td>\n","    </tr>\n","    <tr>\n","      <td>11300</td>\n","      <td>0.836500</td>\n","    </tr>\n","    <tr>\n","      <td>11400</td>\n","      <td>0.850800</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>0.864600</td>\n","    </tr>\n","    <tr>\n","      <td>11600</td>\n","      <td>0.838400</td>\n","    </tr>\n","    <tr>\n","      <td>11700</td>\n","      <td>0.808600</td>\n","    </tr>\n","    <tr>\n","      <td>11800</td>\n","      <td>0.856600</td>\n","    </tr>\n","    <tr>\n","      <td>11900</td>\n","      <td>0.845000</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>0.872600</td>\n","    </tr>\n","    <tr>\n","      <td>12100</td>\n","      <td>0.906500</td>\n","    </tr>\n","    <tr>\n","      <td>12200</td>\n","      <td>0.890800</td>\n","    </tr>\n","    <tr>\n","      <td>12300</td>\n","      <td>0.874900</td>\n","    </tr>\n","    <tr>\n","      <td>12400</td>\n","      <td>0.887900</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>0.832600</td>\n","    </tr>\n","    <tr>\n","      <td>12600</td>\n","      <td>0.843700</td>\n","    </tr>\n","    <tr>\n","      <td>12700</td>\n","      <td>0.844200</td>\n","    </tr>\n","    <tr>\n","      <td>12800</td>\n","      <td>0.838000</td>\n","    </tr>\n","    <tr>\n","      <td>12900</td>\n","      <td>0.867400</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>0.866800</td>\n","    </tr>\n","    <tr>\n","      <td>13100</td>\n","      <td>0.795200</td>\n","    </tr>\n","    <tr>\n","      <td>13200</td>\n","      <td>0.832500</td>\n","    </tr>\n","    <tr>\n","      <td>13300</td>\n","      <td>0.896100</td>\n","    </tr>\n","    <tr>\n","      <td>13400</td>\n","      <td>0.842000</td>\n","    </tr>\n","    <tr>\n","      <td>13500</td>\n","      <td>0.817000</td>\n","    </tr>\n","    <tr>\n","      <td>13600</td>\n","      <td>0.876300</td>\n","    </tr>\n","    <tr>\n","      <td>13700</td>\n","      <td>0.800400</td>\n","    </tr>\n","    <tr>\n","      <td>13800</td>\n","      <td>0.871300</td>\n","    </tr>\n","    <tr>\n","      <td>13900</td>\n","      <td>0.897000</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>0.903100</td>\n","    </tr>\n","    <tr>\n","      <td>14100</td>\n","      <td>0.863000</td>\n","    </tr>\n","    <tr>\n","      <td>14200</td>\n","      <td>0.835900</td>\n","    </tr>\n","    <tr>\n","      <td>14300</td>\n","      <td>0.895400</td>\n","    </tr>\n","    <tr>\n","      <td>14400</td>\n","      <td>0.805600</td>\n","    </tr>\n","    <tr>\n","      <td>14500</td>\n","      <td>0.824600</td>\n","    </tr>\n","    <tr>\n","      <td>14600</td>\n","      <td>0.830500</td>\n","    </tr>\n","    <tr>\n","      <td>14700</td>\n","      <td>0.811000</td>\n","    </tr>\n","    <tr>\n","      <td>14800</td>\n","      <td>0.834800</td>\n","    </tr>\n","    <tr>\n","      <td>14900</td>\n","      <td>0.845800</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>0.830100</td>\n","    </tr>\n","    <tr>\n","      <td>15100</td>\n","      <td>0.866800</td>\n","    </tr>\n","    <tr>\n","      <td>15200</td>\n","      <td>0.807400</td>\n","    </tr>\n","    <tr>\n","      <td>15300</td>\n","      <td>0.802100</td>\n","    </tr>\n","    <tr>\n","      <td>15400</td>\n","      <td>0.847500</td>\n","    </tr>\n","    <tr>\n","      <td>15500</td>\n","      <td>0.803900</td>\n","    </tr>\n","    <tr>\n","      <td>15600</td>\n","      <td>0.838800</td>\n","    </tr>\n","    <tr>\n","      <td>15700</td>\n","      <td>0.801000</td>\n","    </tr>\n","    <tr>\n","      <td>15800</td>\n","      <td>0.864200</td>\n","    </tr>\n","    <tr>\n","      <td>15900</td>\n","      <td>0.783300</td>\n","    </tr>\n","    <tr>\n","      <td>16000</td>\n","      <td>0.817000</td>\n","    </tr>\n","    <tr>\n","      <td>16100</td>\n","      <td>0.851000</td>\n","    </tr>\n","    <tr>\n","      <td>16200</td>\n","      <td>0.883500</td>\n","    </tr>\n","    <tr>\n","      <td>16300</td>\n","      <td>0.907900</td>\n","    </tr>\n","    <tr>\n","      <td>16400</td>\n","      <td>0.810900</td>\n","    </tr>\n","    <tr>\n","      <td>16500</td>\n","      <td>0.836100</td>\n","    </tr>\n","    <tr>\n","      <td>16600</td>\n","      <td>0.838100</td>\n","    </tr>\n","    <tr>\n","      <td>16700</td>\n","      <td>0.830100</td>\n","    </tr>\n","    <tr>\n","      <td>16800</td>\n","      <td>0.797500</td>\n","    </tr>\n","    <tr>\n","      <td>16900</td>\n","      <td>0.850100</td>\n","    </tr>\n","    <tr>\n","      <td>17000</td>\n","      <td>0.813500</td>\n","    </tr>\n","    <tr>\n","      <td>17100</td>\n","      <td>0.835600</td>\n","    </tr>\n","    <tr>\n","      <td>17200</td>\n","      <td>0.849800</td>\n","    </tr>\n","    <tr>\n","      <td>17300</td>\n","      <td>0.877500</td>\n","    </tr>\n","    <tr>\n","      <td>17400</td>\n","      <td>0.873900</td>\n","    </tr>\n","    <tr>\n","      <td>17500</td>\n","      <td>0.794300</td>\n","    </tr>\n","    <tr>\n","      <td>17600</td>\n","      <td>0.814600</td>\n","    </tr>\n","    <tr>\n","      <td>17700</td>\n","      <td>0.800700</td>\n","    </tr>\n","    <tr>\n","      <td>17800</td>\n","      <td>0.881600</td>\n","    </tr>\n","    <tr>\n","      <td>17900</td>\n","      <td>0.839800</td>\n","    </tr>\n","    <tr>\n","      <td>18000</td>\n","      <td>0.833600</td>\n","    </tr>\n","    <tr>\n","      <td>18100</td>\n","      <td>0.833200</td>\n","    </tr>\n","    <tr>\n","      <td>18200</td>\n","      <td>0.825900</td>\n","    </tr>\n","    <tr>\n","      <td>18300</td>\n","      <td>0.894700</td>\n","    </tr>\n","    <tr>\n","      <td>18400</td>\n","      <td>0.855300</td>\n","    </tr>\n","    <tr>\n","      <td>18500</td>\n","      <td>0.843700</td>\n","    </tr>\n","    <tr>\n","      <td>18600</td>\n","      <td>0.802100</td>\n","    </tr>\n","    <tr>\n","      <td>18700</td>\n","      <td>0.846400</td>\n","    </tr>\n","    <tr>\n","      <td>18800</td>\n","      <td>0.796700</td>\n","    </tr>\n","    <tr>\n","      <td>18900</td>\n","      <td>0.811600</td>\n","    </tr>\n","    <tr>\n","      <td>19000</td>\n","      <td>0.782400</td>\n","    </tr>\n","    <tr>\n","      <td>19100</td>\n","      <td>0.805800</td>\n","    </tr>\n","    <tr>\n","      <td>19200</td>\n","      <td>0.825500</td>\n","    </tr>\n","    <tr>\n","      <td>19300</td>\n","      <td>0.796300</td>\n","    </tr>\n","    <tr>\n","      <td>19400</td>\n","      <td>0.777500</td>\n","    </tr>\n","    <tr>\n","      <td>19500</td>\n","      <td>0.858500</td>\n","    </tr>\n","    <tr>\n","      <td>19600</td>\n","      <td>0.764900</td>\n","    </tr>\n","    <tr>\n","      <td>19700</td>\n","      <td>0.824200</td>\n","    </tr>\n","    <tr>\n","      <td>19800</td>\n","      <td>0.809800</td>\n","    </tr>\n","    <tr>\n","      <td>19900</td>\n","      <td>0.820200</td>\n","    </tr>\n","    <tr>\n","      <td>20000</td>\n","      <td>0.817700</td>\n","    </tr>\n","    <tr>\n","      <td>20100</td>\n","      <td>0.827000</td>\n","    </tr>\n","    <tr>\n","      <td>20200</td>\n","      <td>0.798900</td>\n","    </tr>\n","    <tr>\n","      <td>20300</td>\n","      <td>0.803500</td>\n","    </tr>\n","    <tr>\n","      <td>20400</td>\n","      <td>0.810700</td>\n","    </tr>\n","    <tr>\n","      <td>20500</td>\n","      <td>0.736600</td>\n","    </tr>\n","    <tr>\n","      <td>20600</td>\n","      <td>0.825700</td>\n","    </tr>\n","    <tr>\n","      <td>20700</td>\n","      <td>0.839200</td>\n","    </tr>\n","    <tr>\n","      <td>20800</td>\n","      <td>0.810900</td>\n","    </tr>\n","    <tr>\n","      <td>20900</td>\n","      <td>0.865300</td>\n","    </tr>\n","    <tr>\n","      <td>21000</td>\n","      <td>0.802900</td>\n","    </tr>\n","    <tr>\n","      <td>21100</td>\n","      <td>0.884100</td>\n","    </tr>\n","    <tr>\n","      <td>21200</td>\n","      <td>0.804800</td>\n","    </tr>\n","    <tr>\n","      <td>21300</td>\n","      <td>0.810400</td>\n","    </tr>\n","    <tr>\n","      <td>21400</td>\n","      <td>0.790700</td>\n","    </tr>\n","    <tr>\n","      <td>21500</td>\n","      <td>0.860600</td>\n","    </tr>\n","    <tr>\n","      <td>21600</td>\n","      <td>0.864200</td>\n","    </tr>\n","    <tr>\n","      <td>21700</td>\n","      <td>0.737400</td>\n","    </tr>\n","    <tr>\n","      <td>21800</td>\n","      <td>0.822800</td>\n","    </tr>\n","    <tr>\n","      <td>21900</td>\n","      <td>0.764200</td>\n","    </tr>\n","    <tr>\n","      <td>22000</td>\n","      <td>0.752200</td>\n","    </tr>\n","    <tr>\n","      <td>22100</td>\n","      <td>0.832900</td>\n","    </tr>\n","    <tr>\n","      <td>22200</td>\n","      <td>0.829300</td>\n","    </tr>\n","    <tr>\n","      <td>22300</td>\n","      <td>0.823200</td>\n","    </tr>\n","    <tr>\n","      <td>22400</td>\n","      <td>0.795400</td>\n","    </tr>\n","    <tr>\n","      <td>22500</td>\n","      <td>0.844800</td>\n","    </tr>\n","    <tr>\n","      <td>22600</td>\n","      <td>0.757600</td>\n","    </tr>\n","    <tr>\n","      <td>22700</td>\n","      <td>0.843500</td>\n","    </tr>\n","    <tr>\n","      <td>22800</td>\n","      <td>0.795000</td>\n","    </tr>\n","    <tr>\n","      <td>22900</td>\n","      <td>0.721300</td>\n","    </tr>\n","    <tr>\n","      <td>23000</td>\n","      <td>0.736900</td>\n","    </tr>\n","    <tr>\n","      <td>23100</td>\n","      <td>0.836100</td>\n","    </tr>\n","    <tr>\n","      <td>23200</td>\n","      <td>0.861700</td>\n","    </tr>\n","    <tr>\n","      <td>23300</td>\n","      <td>0.843600</td>\n","    </tr>\n","    <tr>\n","      <td>23400</td>\n","      <td>0.859200</td>\n","    </tr>\n","    <tr>\n","      <td>23500</td>\n","      <td>0.812500</td>\n","    </tr>\n","    <tr>\n","      <td>23600</td>\n","      <td>0.831600</td>\n","    </tr>\n","    <tr>\n","      <td>23700</td>\n","      <td>0.778100</td>\n","    </tr>\n","    <tr>\n","      <td>23800</td>\n","      <td>0.790800</td>\n","    </tr>\n","    <tr>\n","      <td>23900</td>\n","      <td>0.796400</td>\n","    </tr>\n","    <tr>\n","      <td>24000</td>\n","      <td>0.755100</td>\n","    </tr>\n","    <tr>\n","      <td>24100</td>\n","      <td>0.830300</td>\n","    </tr>\n","    <tr>\n","      <td>24200</td>\n","      <td>0.843200</td>\n","    </tr>\n","    <tr>\n","      <td>24300</td>\n","      <td>0.807300</td>\n","    </tr>\n","    <tr>\n","      <td>24400</td>\n","      <td>0.808900</td>\n","    </tr>\n","    <tr>\n","      <td>24500</td>\n","      <td>0.802500</td>\n","    </tr>\n","    <tr>\n","      <td>24600</td>\n","      <td>0.854500</td>\n","    </tr>\n","    <tr>\n","      <td>24700</td>\n","      <td>0.805500</td>\n","    </tr>\n","    <tr>\n","      <td>24800</td>\n","      <td>0.851100</td>\n","    </tr>\n","    <tr>\n","      <td>24900</td>\n","      <td>0.775900</td>\n","    </tr>\n","    <tr>\n","      <td>25000</td>\n","      <td>0.812200</td>\n","    </tr>\n","    <tr>\n","      <td>25100</td>\n","      <td>0.854500</td>\n","    </tr>\n","    <tr>\n","      <td>25200</td>\n","      <td>0.795200</td>\n","    </tr>\n","    <tr>\n","      <td>25300</td>\n","      <td>0.780800</td>\n","    </tr>\n","    <tr>\n","      <td>25400</td>\n","      <td>0.831100</td>\n","    </tr>\n","    <tr>\n","      <td>25500</td>\n","      <td>0.862900</td>\n","    </tr>\n","    <tr>\n","      <td>25600</td>\n","      <td>0.804200</td>\n","    </tr>\n","    <tr>\n","      <td>25700</td>\n","      <td>0.858200</td>\n","    </tr>\n","    <tr>\n","      <td>25800</td>\n","      <td>0.787200</td>\n","    </tr>\n","    <tr>\n","      <td>25900</td>\n","      <td>0.841800</td>\n","    </tr>\n","    <tr>\n","      <td>26000</td>\n","      <td>0.735000</td>\n","    </tr>\n","    <tr>\n","      <td>26100</td>\n","      <td>0.740800</td>\n","    </tr>\n","    <tr>\n","      <td>26200</td>\n","      <td>0.798500</td>\n","    </tr>\n","    <tr>\n","      <td>26300</td>\n","      <td>0.775100</td>\n","    </tr>\n","    <tr>\n","      <td>26400</td>\n","      <td>0.803100</td>\n","    </tr>\n","    <tr>\n","      <td>26500</td>\n","      <td>0.847000</td>\n","    </tr>\n","    <tr>\n","      <td>26600</td>\n","      <td>0.822000</td>\n","    </tr>\n","    <tr>\n","      <td>26700</td>\n","      <td>0.845600</td>\n","    </tr>\n","    <tr>\n","      <td>26800</td>\n","      <td>0.816700</td>\n","    </tr>\n","    <tr>\n","      <td>26900</td>\n","      <td>0.784600</td>\n","    </tr>\n","    <tr>\n","      <td>27000</td>\n","      <td>0.754000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to /content/drive/My Drive/Colab Notebooks/DeepLearningVision/GPTresults/checkpoint-5000\n","Configuration saved in /content/drive/My Drive/Colab Notebooks/DeepLearningVision/GPTresults/checkpoint-5000/config.json\n","Model weights saved in /content/drive/My Drive/Colab Notebooks/DeepLearningVision/GPTresults/checkpoint-5000/pytorch_model.bin\n","Saving model checkpoint to /content/drive/My Drive/Colab Notebooks/DeepLearningVision/GPTresults/checkpoint-10000\n","Configuration saved in /content/drive/My Drive/Colab Notebooks/DeepLearningVision/GPTresults/checkpoint-10000/config.json\n","Model weights saved in /content/drive/My Drive/Colab Notebooks/DeepLearningVision/GPTresults/checkpoint-10000/pytorch_model.bin\n","Saving model checkpoint to /content/drive/My Drive/Colab Notebooks/DeepLearningVision/GPTresults/checkpoint-15000\n","Configuration saved in /content/drive/My Drive/Colab Notebooks/DeepLearningVision/GPTresults/checkpoint-15000/config.json\n","Model weights saved in /content/drive/My Drive/Colab Notebooks/DeepLearningVision/GPTresults/checkpoint-15000/pytorch_model.bin\n","Saving model checkpoint to /content/drive/My Drive/Colab Notebooks/DeepLearningVision/GPTresults/checkpoint-20000\n","Configuration saved in /content/drive/My Drive/Colab Notebooks/DeepLearningVision/GPTresults/checkpoint-20000/config.json\n","Model weights saved in /content/drive/My Drive/Colab Notebooks/DeepLearningVision/GPTresults/checkpoint-20000/pytorch_model.bin\n","Saving model checkpoint to /content/drive/My Drive/Colab Notebooks/DeepLearningVision/GPTresults/checkpoint-25000\n","Configuration saved in /content/drive/My Drive/Colab Notebooks/DeepLearningVision/GPTresults/checkpoint-25000/config.json\n","Model weights saved in /content/drive/My Drive/Colab Notebooks/DeepLearningVision/GPTresults/checkpoint-25000/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=27000, training_loss=0.8708230763188115, metrics={'train_runtime': 3195.1037, 'train_samples_per_second': 8.45, 'train_steps_per_second': 8.45, 'total_flos': 2797151616000000.0, 'train_loss': 0.8708230763188115, 'epoch': 1.0})"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# Save the fine-tune model\n","\n","torch.save(model, '/content/drive/My Drive/Colab Notebooks/DeepLearningVision/GPTresults/model')"],"metadata":{"id":"jVV255qALBnn","executionInfo":{"status":"ok","timestamp":1656434217755,"user_tz":-120,"elapsed":1622,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}}},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":["## 5. Generate Text\n","There are different decoding methods for language generation with Transformers. We will compare 4 different decoding approachs using the fine-tune GPT-2 model. The decoding methods adapted from https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/02_how_to_generate.ipynb#scrollTo=Y77H5m4ZmhEX"],"metadata":{"id":"FFQ3fgV2FzaD"}},{"cell_type":"code","source":["generated = tokenizer(\"Internet explorer \", return_tensors=\"pt\").input_ids.cuda()\n","generated"],"metadata":{"id":"WOzP0xGsAHzM","executionInfo":{"status":"ok","timestamp":1656431459097,"user_tz":-120,"elapsed":560,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["### Greedy Search Approach\n","Greedy search simply selects the word with the highest probability as its next word at each timestep.\n","\n","![Greedy Search](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/greedy_search.png)\n"],"metadata":{"id":"95xwwIELF4af"}},{"cell_type":"markdown","source":["In greedy search we just try to predict the next words without any other parameter to consider. As a result, it would creates quite random word sequence in a sentence."],"metadata":{"id":"zaauAw4qNa5u"}},{"cell_type":"code","source":["greedy_outpus = model.generate(generated, do_sample=True, \n","                                max_length=330, num_return_sequences=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0SdCznGExuu","executionInfo":{"status":"ok","timestamp":1656432646362,"user_tz":-120,"elapsed":1897,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}},"outputId":"32eff8e4-26db-406f-ecf3-876eb0133145"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]}]},{"cell_type":"code","source":["for i, output in enumerate(greedy_outpus):\n","    print(\"{}: {}\".format(i, tokenizer.decode(output, skip_special_tokens=True)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iZ2mfc3MExxX","executionInfo":{"status":"ok","timestamp":1656432653901,"user_tz":-120,"elapsed":815,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}},"outputId":"0599824d-decd-4a2e-c193-e4be95602ba9"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["0: Internet explorer ipsi to deliver content ad free software from ipsi be get their start with the release of one of the favorite advertising tool adobe systems corp lt href http www co uk financequotelookup jhtml ticker adaplz qtype sym infotype info qcat news gt adai lt gt aim to replace the internet advertising\n"]}]},{"cell_type":"markdown","source":["### Beam Search Approach\n","Beam search reduces the risk of missing hidden high probability word sequences by keeping the most likely `num_beams` of hypotheses at each time step and eventually choosing the hypothesis that has the overall highest probability. Let's illustrate with `num_beams=2`:\n","\n","![Beam search](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/beam_search.png)"],"metadata":{"id":"aEEv0SNBF_OX"}},{"cell_type":"markdown","source":["We use the optimum number of beam with size of 6 and to avoid redudant word sequence we limit it through n_gram with size of 2. The number of beam used to define how big the branches of the sequence of the next predicted word. The bigger the size, more word options will be appeared. However, it does not mean that higher beam size can gives better result, as it is will make more random sentence which cause the sentence loose the meaning and context."],"metadata":{"id":"Rl4VPzkCN2wQ"}},{"cell_type":"code","source":["beam_outpus = model.generate(generated, do_sample=True, \n","                                max_length=330, num_beams=6, no_repeat_ngram_size=2, num_return_sequences=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M4VPEdeuAoo1","executionInfo":{"status":"ok","timestamp":1656432471931,"user_tz":-120,"elapsed":1053,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}},"outputId":"94dd9137-50d2-43b4-de62-700cd8fbbe6c"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]}]},{"cell_type":"code","source":["for i, output in enumerate(beam_outpus):\n","    print(\"{}: {}\".format(i, tokenizer.decode(output, skip_special_tokens=True)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5iqDSCMgJd-Z","executionInfo":{"status":"ok","timestamp":1656432473595,"user_tz":-120,"elapsed":3,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}},"outputId":"4afc427d-a604-47a5-d000-5fa8b3cc0996"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["0: Internet explorer ietf warn of security flaw in windows xp service pack microsoft on tuesday warn that security hole could allow an attacker to take control of user computer and steal their personal information\n"]}]},{"cell_type":"markdown","source":["### Top-K Sampling Approach\n","In *Top-K* sampling, the *K* most likely next words are filtered and the probability mass is redistributed among only those *K* next words. \n","GPT2 adopted this sampling scheme, which was one of the reasons for its success in story generation. \n","\n","In here, we select the top 25 words that most likely appears following the token word."],"metadata":{"id":"hmaW7j8lGEtk"}},{"cell_type":"code","source":["topk_outputs = model.generate(generated, do_sample=True, top_k=25, \n","                                max_length=330, temperature=0.5, num_return_sequences=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AOkj85M7FJDq","executionInfo":{"status":"ok","timestamp":1656435343175,"user_tz":-120,"elapsed":1545,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}},"outputId":"60ecb1a6-6e9f-47fd-ae2a-5e3e6eab2837"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]}]},{"cell_type":"code","source":["for i, output in enumerate(topk_outputs):\n","    print(\"{}: {}\".format(i, tokenizer.decode(output, skip_special_tokens=True)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Et2DYvUFJFv","executionInfo":{"status":"ok","timestamp":1656435346256,"user_tz":-120,"elapsed":3,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}},"outputId":"93bbab71-60cd-42e1-cbfc-f21c445cb588"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["0: Internet explorer ix to be launch next week in the late round of the open source enterprise linux series the xm release be expect to be available on the next os and will be available for download in the next few day\n"]}]},{"cell_type":"markdown","source":["### Top-p (nucleus) Sampling Approach\n","Instead of sampling only from the most likely *K* words, in *Top-p* sampling chooses from the smallest possible set of words whose cumulative probability exceeds the probability *p*.\n","\n","In here, we can take a bigger size of top-k sampling because we will give penalty using top-p probability. It means that a word will not be selected or consider if the probability of two words appear together below 95%."],"metadata":{"id":"Ab8o8nyHGJ0d"}},{"cell_type":"code","source":["nucleus_outputs = model.generate(generated, do_sample=True, top_k=100, \n","                                max_length=330, top_p=0.95, temperature=0.5, num_return_sequences=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RQMrx1eeAocR","executionInfo":{"status":"ok","timestamp":1656432444634,"user_tz":-120,"elapsed":967,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}},"outputId":"6941d559-ac1c-401a-c8b2-6b3856a15577"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]}]},{"cell_type":"code","source":["for i, output in enumerate(nucleus_outputs):\n","    print(\"{}: {}\".format(i, tokenizer.decode(output, skip_special_tokens=True)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pz5QxcB_AofF","executionInfo":{"status":"ok","timestamp":1656432447498,"user_tz":-120,"elapsed":4,"user":{"displayName":"Amelia Budiharto","userId":"06889310582528002746"}},"outputId":"84a152d5-e885-407e-91fe-bf7cef24c2d0"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["0: Internet explorer ietf say it have develop new web browser that will help user find and download file on their hard drive\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"JS0daWOOAomY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Conclusion\n","As a conclusion, each decoding methods have it flaws. The top-K and top-p sampling is a good approach to avoid repetitive word sequences. In addition, the top-p approach able to generate more fluid sentence compare to top-K sampling. However, according to other researcher, if we have more domain specific text, beam search could be a better choice since it could limit the choice of word options to generate the next word from our token.\n","\n","As model comparison with RNN, the pre-trained model surely able to generate better sentence since it is include more vocabulary in the initial trained model. Therefore, fine-tune a pre-trained model can be an alternative option if we do not need to generate a domain specific text."],"metadata":{"id":"bEq2KuNZQS0D"}}]}